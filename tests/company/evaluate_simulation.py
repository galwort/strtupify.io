"""Evaluate simulation output generated by full_game_simulation.py.

Usage:
    python tests/company/evaluate_simulation.py [--input path/to/output.json]
"""

from __future__ import annotations

import argparse
import json
import statistics
from pathlib import Path
from typing import Iterable, List


def flatten(items: Iterable[Iterable[float]]) -> List[float]:
    out: List[float] = []
    for chunk in items:
        out.extend(chunk)
    return out


def safe_mean(values: Iterable[float]) -> float:
    data = list(values)
    return statistics.mean(data) if data else 0.0


def safe_median(values: Iterable[float]) -> float:
    data = list(values)
    return statistics.median(data) if data else 0.0


def load(path: Path) -> dict:
    with path.open("r", encoding="utf-8") as fh:
        return json.load(fh)


def evaluate(data: dict) -> dict:
    companies = data.get("companies", [])
    loan_amounts = [c.get("company", {}).get("loan_amount", 0.0) for c in companies]
    first_payments = [c.get("company", {}).get("first_payment_amount", 0.0) for c in companies]
    first_payment_days = [c.get("company", {}).get("first_payment_days", 0) for c in companies]
    completion_hours = [c.get("company", {}).get("time_to_complete_hours", 0.0) for c in companies]

    skill_levels = flatten(
        (
            [s.get("level", 0) for s in emp.get("skillsets", [])]
            for comp in companies
            for emp in comp.get("employees", [])
        )
    )

    work_item_counts = [len(comp.get("work_items", [])) for comp in companies]
    blocker_counts = flatten(
        ([wi.get("blocker_count", 0)] for comp in companies for wi in comp.get("work_items", []))
    )
    rates = flatten(
        ([wi.get("rate_per_hour", 0.0)] for comp in companies for wi in comp.get("work_items", []))
    )

    return {
        "companies": len(companies),
        "loan_amount_mean": safe_mean(loan_amounts),
        "loan_amount_median": safe_median(loan_amounts),
        "first_payment_mean": safe_mean(first_payments),
        "first_payment_median": safe_median(first_payments),
        "first_payment_days_mean": safe_mean(first_payment_days),
        "first_payment_days_median": safe_median(first_payment_days),
        "skill_level_mean": safe_mean(skill_levels),
        "skill_level_median": safe_median(skill_levels),
        "work_items_mean": safe_mean(work_item_counts),
        "work_items_median": safe_median(work_item_counts),
        "blockers_mean": safe_mean(blocker_counts),
        "blockers_median": safe_median(blocker_counts),
        "rates_mean": safe_mean(rates),
        "rates_median": safe_median(rates),
        "completion_hours_mean": safe_mean(completion_hours),
        "completion_hours_median": safe_median(completion_hours),
    }


def main() -> None:
    default_input = (Path(__file__).resolve().parent / "archive" / "output.json").as_posix()
    parser = argparse.ArgumentParser(description="Evaluate simulation output JSON")
    parser.add_argument("--input", type=str, default=default_input, help="Path to simulation JSON output")
    args = parser.parse_args()

    path = Path(args.input)
    if not path.exists():
        raise SystemExit(f"Input file not found: {path}")

    metrics = evaluate(load(path))

    print("Simulation evaluation:\n")
    for key, value in metrics.items():
        if key == "companies":
            print(f"{key}: {int(value)}")
        else:
            print(f"{key}: {value:.2f}")


if __name__ == "__main__":
    main()
